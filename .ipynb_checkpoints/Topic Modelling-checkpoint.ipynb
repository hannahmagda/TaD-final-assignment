{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d688362d",
   "metadata": {},
   "source": [
    "TOPIC MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dab6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4dc66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>header</th>\n",
       "      <th>information</th>\n",
       "      <th>speech</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Remarks by OPEC Secretary General</td>\n",
       "      <td>Delivered by HE Haitham Al Ghais, OPEC Secreta...</td>\n",
       "      <td>Your Excellency Mr. Chairman, Excellencies, la...</td>\n",
       "      <td>HE Haitham Al Ghais</td>\n",
       "      <td>https://www.opec.org/opec_web/en/press_room/71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Address by OPEC Secretary General</td>\n",
       "      <td>Delivered by HE Haitham Al Ghais, OPEC Secreta...</td>\n",
       "      <td>Honourable Prime Minister, Excellencies, ladie...</td>\n",
       "      <td>HE Haitham Al Ghais</td>\n",
       "      <td>https://www.opec.org/opec_web/en/press_room/71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Address by OPEC Secretary General</td>\n",
       "      <td>Delivered by HE Haitham Al Ghais, OPEC Secreta...</td>\n",
       "      <td>Your Highness, Excellencies, Distinguished gue...</td>\n",
       "      <td>HE Haitham Al Ghais</td>\n",
       "      <td>https://www.opec.org/opec_web/en/press_room/71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>OPEC Statement to the UN Climate Change Confer...</td>\n",
       "      <td>Delivered by HE Haitham Al Ghais, OPEC Secreta...</td>\n",
       "      <td>Madame President, distinguished delegates, Th...</td>\n",
       "      <td>HE Haitham Al Ghais</td>\n",
       "      <td>https://www.opec.org/opec_web/en/press_room/70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>Keynote address by OPEC Secretary General</td>\n",
       "      <td>Delivered by HE Mohammad Sanusi Barkindo, OPEC...</td>\n",
       "      <td>Excellencies, ladies and gentlemen,\\n\\n It is ...</td>\n",
       "      <td>HE Mohammad Sanusi Barkindo</td>\n",
       "      <td>https://www.opec.org/opec_web/en/press_room/69...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                             header  \\\n",
       "0  2023                  Remarks by OPEC Secretary General   \n",
       "1  2023                  Address by OPEC Secretary General   \n",
       "2  2023                  Address by OPEC Secretary General   \n",
       "3  2022  OPEC Statement to the UN Climate Change Confer...   \n",
       "4  2022          Keynote address by OPEC Secretary General   \n",
       "\n",
       "                                         information  \\\n",
       "0  Delivered by HE Haitham Al Ghais, OPEC Secreta...   \n",
       "1  Delivered by HE Haitham Al Ghais, OPEC Secreta...   \n",
       "2  Delivered by HE Haitham Al Ghais, OPEC Secreta...   \n",
       "3  Delivered by HE Haitham Al Ghais, OPEC Secreta...   \n",
       "4  Delivered by HE Mohammad Sanusi Barkindo, OPEC...   \n",
       "\n",
       "                                              speech  \\\n",
       "0  Your Excellency Mr. Chairman, Excellencies, la...   \n",
       "1  Honourable Prime Minister, Excellencies, ladie...   \n",
       "2  Your Highness, Excellencies, Distinguished gue...   \n",
       "3   Madame President, distinguished delegates, Th...   \n",
       "4  Excellencies, ladies and gentlemen,\\n\\n It is ...   \n",
       "\n",
       "                          name  \\\n",
       "0          HE Haitham Al Ghais   \n",
       "1          HE Haitham Al Ghais   \n",
       "2          HE Haitham Al Ghais   \n",
       "3          HE Haitham Al Ghais   \n",
       "4  HE Mohammad Sanusi Barkindo   \n",
       "\n",
       "                                                link  \n",
       "0  https://www.opec.org/opec_web/en/press_room/71...  \n",
       "1  https://www.opec.org/opec_web/en/press_room/71...  \n",
       "2  https://www.opec.org/opec_web/en/press_room/71...  \n",
       "3  https://www.opec.org/opec_web/en/press_room/70...  \n",
       "4  https://www.opec.org/opec_web/en/press_room/69...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "\n",
    "data = pd.read_csv('speeches.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46879232",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Need to clean each speech: dropping first and last sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37dbb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['speech'] = data['speech'].str.contains('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc59260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMPEZAMOS CON TOPIC MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db58191",
   "metadata": {},
   "source": [
    "Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e904652f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Corpus\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    corpus.append({\n",
    "        'year': str(row['year']),\n",
    "        'id': f\"{str(row['year'])}\\n_{index + 1}\",\n",
    "        'document': row['speech']\n",
    "    })\n",
    "    \n",
    "corpus_df = pd.DataFrame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f650bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023\\n_1</td>\n",
       "      <td>Your Excellency Mr. Chairman, Excellencies, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023\\n_2</td>\n",
       "      <td>Honourable Prime Minister, Excellencies, ladie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2023\\n_3</td>\n",
       "      <td>Your Highness, Excellencies, Distinguished gue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022\\n_4</td>\n",
       "      <td>Madame President, distinguished delegates, Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022\\n_5</td>\n",
       "      <td>Excellencies, ladies and gentlemen,\\n\\n It is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year        id                                           document\n",
       "0  2023  2023\\n_1  Your Excellency Mr. Chairman, Excellencies, la...\n",
       "1  2023  2023\\n_2  Honourable Prime Minister, Excellencies, ladie...\n",
       "2  2023  2023\\n_3  Your Highness, Excellencies, Distinguished gue...\n",
       "3  2022  2022\\n_4   Madame President, distinguished delegates, Th...\n",
       "4  2022  2022\\n_5  Excellencies, ladies and gentlemen,\\n\\n It is ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235c6ef",
   "metadata": {},
   "source": [
    "Lemmatization and Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e48ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for Lemmatization and Stopwords\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Downloading the stopwords dataset\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Download the spaCy English model\n",
    "# spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef88e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a function to remove stopwords, symbols and lemmatize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "    lemmatized_words = [token.lemma_ for token in nlp(\" \".join(filtered_words))]\n",
    "    return lemmatized_words\n",
    "\n",
    "# Apply the function to the 'document' column\n",
    "corpus_df['document'] = corpus_df['document'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a7b31",
   "metadata": {},
   "source": [
    "Topic Modeling: Latent Dirichlet Allocation (LDA) using gensim library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c1b91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for Topic Modeling\n",
    "\n",
    "from gensim import corpora, models\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "549fd4b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'token2id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m extra_words \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPEC\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m extra_words:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bag_words\u001b[38;5;241m.\u001b[39mtoken2id:\n\u001b[1;32m      6\u001b[0m         bag_words\u001b[38;5;241m.\u001b[39madd_documents([[word]])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Topic Modeling\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Creating a bag of words and applying it to each document\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'token2id'"
     ]
    }
   ],
   "source": [
    "# Adding extra words to the bag of words\n",
    "bag_words = []\n",
    "extra_words = ['OPEC']\n",
    "for word in extra_words:\n",
    "    if word not in bag_words.token2id:\n",
    "        bag_words.add_documents([[word]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Topic Modeling\n",
    "\n",
    "# Creating a bag of words and applying it to each document\n",
    "bag_words = corpora.Dictionary(corpus_df['document'])\n",
    "corpus = [bag_words.doc2bow(doc) for doc in corpus_df['document']]\n",
    "\n",
    "# LDA model\n",
    "lda_model = models.LdaModel(corpus, num_topics = 5, id2word = bag_words, passes = 10)\n",
    "\n",
    "# Printing the topics\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print (f'Topic {idx}: {topic}')\n",
    "# Assigning topics to documents\n",
    "corpus_df['topic'] = [max(lda_model[doc], key=lambda x: x[1])[0] for doc in corpus]\n",
    "# Printing\n",
    "# print(corpus_df[['document', 'topic']])\n",
    "\n",
    "# Get the top terms for each topic\n",
    "top_terms_per_topic = lda_model.show_topics(num_topics=5, num_words=5, formatted=False)\n",
    "\n",
    "# Print the top 5 words and their probabilities for each topic\n",
    "for topic_id, topic_words in top_terms_per_topic:\n",
    "    print(f'Topic {topic_id}:')\n",
    "    for word, prob in topic_words:\n",
    "        print(f'  {word}: {prob:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08644441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e5b7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "# Assuming 'corpus' and 'dictionary' are already created\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus, num_topics=5, id2word=bag_words, passes=15)\n",
    "\n",
    "# Get the top terms for each topic\n",
    "top_terms_per_topic = lda_model.show_topics(num_topics=5, num_words=5, formatted=False)\n",
    "\n",
    "# Print the top 5 words and their probabilities for each topic\n",
    "for topic_id, topic_words in top_terms_per_topic:\n",
    "    print(f'Topic {topic_id}:')\n",
    "    for word, prob in topic_words:\n",
    "        print(f'  {word}: {prob:.4f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0331c2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5615529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb229d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88598657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c6ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e5b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af6348e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241fa79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c8a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
