---
title: "Final Project"
author: "Carlo Greß"
date: "2023-11-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rvest)
library(dplyr)
library(purrr)
library(XML)
```

### Scraping all links available for the years 2003 to 2023
```{r}
url <- "https://www.opec.org/opec_web/en/press_room/307.htm"

# Read the HTML content of the webpage
page <- read_html(url)

# Locate the div with the class "archives" and then select all 'option' elements within it
options <- page %>% html_nodes(".archives option")

# Extract both 'value' attribute and text content
data <- data.frame(
  value = options %>% html_attr("value"),
  year = options %>% html_text()
)

# Removing first row since it is not including a linke
data <- data %>% slice(-1)

# Adding shared first part of the url to all hrefs
data <- data %>% mutate(value = paste0("opec.org", value))

# Print the extracted data
print(data)
```

```{r}
data$value <- paste0("https://www.", data$value)
```


```{r}

# Function to extract links from a single URL
extract_links <- function(url) {
  page <- read_html(url)
  all_links <- page %>% html_nodes('.slim.articles a')
  links <- html_attr(all_links, "href")
  return(links)
}

# Apply the function to each URL in the DataFrame
all_extracted_links <- data %>%
  mutate(extracted_links = map(value, extract_links)) %>%
  pull(extracted_links) %>%
  unlist()
all_extracted_links <- paste0("https://www.opec.org", all_extracted_links)

all_extracted_links <- all_extracted_links[!grepl("^https://www.opec.orghttp://", all_extracted_links)]

# View the modified character vector
print(all_extracted_links)


```

```{r}

# 
# extract_text_from_link <- function(url) {
#   Sys.sleep(2)  # Introduce a 2-second delay
#   webpage <- read_html(url)
#   parsed_nodes <- html_nodes(webpage, xpath = '//p')
#   speech_text <- html_text(parsed_nodes)
#   return(speech_text)
# }
# 
# all_speech_text <- lapply(all_extracted_links, extract_text_from_link)
# 
# head(all_speech_text)
# 
# 
# combined_text <- unlist(all_speech_text)
# 
# # Save the text to a text file
# writeLines(combined_text, "output_text.txt")

```




Code to preserve the years next to the text
```{r}
# Function to extract links from a single URL
extract_links <- function(url) {
  page <- read_html(url)
  all_links <- page %>% html_nodes('.slim.articles a')
  links <- html_attr(all_links, "href")
  return(links)
}

# Apply the function to each URL in the DataFrame
df <- data %>%
  mutate(extracted_links = map(value, extract_links)) %>%
  unnest(extracted_links) %>%
  select(-value)  # Remove the original 'value' column

# View the DataFrame with the extracted links in new rows
print(df)

#Prepend "https://www.opec.org" to each link in the 'extracted_links' column
df <- data %>%
  mutate(extracted_links = map(value, extract_links)) %>%
  unnest(extracted_links) %>%
  mutate(extracted_links = paste0("https://www.opec.org", extracted_links)) %>%
  select(-value)  # Remove the original 'value' column


#removing links that start with "https://www.opec.orghttp://"
df$extracted_links <- lapply(df$extracted_links, function(links) {
  links[!grepl("^https://www.opec.orghttp://", links)]
})

#Filter out rows where the 'extracted_links' list column is empty
df <- df %>%
  filter(map_lgl(extracted_links, ~ length(.x) > 0))

#remove row 240 and some more links as they only contain links to pdfs
df <- df[-240, ]

exclude_links <- c(
  "https://www.opec.org/opec_web/en/press_room/414.htm",
  "https://www.opec.org/opec_web/en/press_room/878.htm",
  "https://www.opec.org/opec_web/en/press_room/871.htm"
)

df <- df %>%
  filter(!(extracted_links %in% exclude_links))

print(df)
```


```{r}
#get text with year
# df <- df %>%
#   filter(map_lgl(extracted_links, ~ length(.x) > 0)) %>%  # Remove rows with empty links
#   mutate(all_speech_text = map(extracted_links, extract_text_from_link)) %>%
#   unnest(all_speech_text) %>%
#   select(-extracted_links)  # Remove the original 'extracted_links' column
# 
# # View the modified DataFrame
# print(df)
# 
# write.csv(df, "Text_years.csv", row.names = FALSE)

```



```{r}

# scraper
extract_text_from_link <- function(url) {
  tryCatch(
    {
      Sys.sleep(2)  # Introduce a 2-second delay
      webpage <- read_html(url)
      
      # Extract text from the <h1> element
      header_text <- html_text(html_nodes(webpage, "h1"))
      
      # Extract text from the <h5> element
      information_text <- html_text(html_nodes(webpage, "h5"))
      
      # Extract text from all <p> elements and concatenate into a single string
      speech_text <- paste(html_text(html_nodes(webpage, "p")), collapse = " ")
      
      # Check if speech_text is empty
      if (length(speech_text) == 0) {
        cat("No text extracted for URL:", url, "\n")
        return(NULL)
      }
      
      # Create a data frame with the extracted text
      result_df <- data.frame(header = header_text, information = information_text, speech = speech_text)
      
      return(result_df)
    },
    error = function(e) {
      cat("Error scraping URL:", url, "- Message:", conditionMessage(e), "\n")
      return(NULL)
    }
  )
}

# get speeches
all_speeches <- df %>%
  filter(map_lgl(extracted_links, ~ length(.x) > 0)) %>%
  mutate(all_speech_text = map(extracted_links, extract_text_from_link)) %>%
  unnest(all_speech_text)
  select(-extracted_links)

write.csv(all_speeches, "speeches.csv", row.names = FALSE)

```

### Extracting the names of the speakers

```{r}
library(stringr)

# Extract names using case-insensitive regular expression
all_speeches$name <- str_extract(all_speeches$information, "(?i)by\\s+([^,]+)(?:,\\s+|$)")

# Remove the leading "by " from the extracted names
all_speeches$name <- str_replace(all_speeches$name, "(?i)by\\s+", "")

# Conditionally update names for "OPEC Secretary General"
update_condition <- all_speeches$name == "OPEC Secretary General" & !is.na(all_speeches$information)
all_speeches$name <- ifelse(update_condition, 
                            str_extract(all_speeches$information, "(?i)by\\s+[^,]+,\\s+([^,]+)"), 
                            all_speeches$name)

# Remove "by OPEC Secretary General," from some cells
all_speeches$name <- str_replace(all_speeches$name, "(?i)by\\s+OPEC Secretary General,", "")

# Remove comma
all_speeches$name <- str_replace_all(all_speeches$name, ",", "")

# Display the result
print(all_speeches)
```

### Sometimes, after the first "by", OPEC Secretary General stand in front of the name. The next chunk removes that and stores the name instead. 
```{r}
all_speeches <- all_speeches %>%
  mutate(
    name = case_when(
      name %in% c("OPEC Secretary General", "OPEC's Secretary General", "OPEC's Director of Research Division", "OPEC Conference President") ~ 
        str_trim(str_extract(information, "(?<=,\\s)[^,]+"), side = "both"),
      TRUE ~ str_trim(name, side = "both")
    )
  )

all_speeches$name <- str_replace(all_speeches$name, "by\\s+Secretary General,", "")

print(all_speeches)
```
Some edge cases are hard to rename with a condition, hence we manually insert the names
```{r}
all_speeches <- all_speeches %>%
  mutate(
    name = case_when(
      row_number() == 215 ~ "HE Abdulla Salam El-Badri",
      row_number() == 250 ~ NA_character_,
      row_number() == 309 ~ "Dr Adnan Shibab-Eldin",
      row_number() == 324 ~ NA_character_,
      TRUE ~ name
    )
  )

# Display the result
print(all_speeches)

write.csv(all_speeches, "speeches.csv", row.names = FALSE)
```

### Extracting speaker's role and type of speech

```{r}

# Adding type of speech using the header variable 

all_speeches <- all_speeches %>%
  mutate(type = ifelse(grepl('by', header), sub(' by.*', '', header), sub('^(\\S+\\s+\\S+).*', '\\1', header)))

# Adding role of speaker 

all_speeches <- all_speeches %>%
  mutate(role = ifelse(grepl('by', header), sub('.* by\\s+', '', header), sub('.*? by\\s+', '', header)))

all_speeches$role <- sub('^[^A-Z]+\\s*', '', all_speeches$role)
all_speeches$role <- sub('.*Secretary General.*', 'Secretary General', all_speeches$role)

# Manually adding Secretary General to Mr Silva Calderon since pattern differs slightly
all_speeches <- all_speeches %>%
  mutate(role = ifelse(name %in% c('Dr. Alvaro Silva-Calderón', 'Dr. Alvaro Silva Calderón', 'Dr Alvaro Silva-Calderón'), 'Secretary General', role))

all_speeches <- all_speeches %>%
  mutate(role = ifelse(name %in% c('Dr. Edmund M. Daukoru'), 'President of the OPEC Conference', role))

all_speeches <- all_speeches %>%
  mutate(name = gsub('^(\\s*HE|\\s*Dr\\.?|\\s*Mr\\.?)\\s+', '', name))

all_speeches <- all_speeches %>% 
  select(year, header, name, role, type, information, speech)
```

### Extract dates

```{r}
library(stringr)

# Define the regular expression pattern for the specified date formats
date_pattern <- "\\b\\d{1,2} (?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4}\\b"

# Extract dates from the 'information' column and create a new 'date' column
all_speeches$date <- str_extract(all_speeches$information, date_pattern)

# Print the dataframe with the new 'date' column
print(all_speeches[c('information', 'date')])

```


